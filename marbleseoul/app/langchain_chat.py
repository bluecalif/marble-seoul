# -*- coding: utf-8 -*-
"""langchain_chat.py
ê°„ë‹¨í•œ LLM ë˜í¼ â€“ ConversationChain ì œê±°í•˜ì—¬ Pydantic v1/v2 ì¶©ëŒ íšŒí”¼.
"""
from __future__ import annotations

import os
from typing import Any
from dotenv import load_dotenv

# Streamlit secrets ì§€ì›ì„ ìœ„í•œ import
try:
    import streamlit as st
    HAS_STREAMLIT = True
except ImportError:
    HAS_STREAMLIT = False

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ - ë¡œì»¬ ê°œë°œìš©)
load_dotenv()

try:
    # ìµœì‹  langchain-openai íŒ¨í‚¤ì§€ êµ¬ì¡° ìš°ì„ 
    from langchain_openai import ChatOpenAI  # type: ignore
except ImportError:
    try:
        from langchain.chat_models import ChatOpenAI  # type: ignore
    except ImportError:
        from langchain.llms import OpenAIChat as ChatOpenAI  # type: ignore


class EchoResponder:
    """OPENAI_API_KEY ì—†ì„ ì‹œ ë‹¨ìˆœ ì—ì½”."""

    def invoke(self, prompt: str, **_: Any) -> str:  # noqa: D401
        return f"[echo] {prompt}"


_llm: Any | None = None


def get_api_key() -> str | None:
    """API í‚¤ë¥¼ ë¡œì»¬(.env) ë˜ëŠ” Streamlit Cloud(secrets)ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    # 1. ë¡œì»¬ í™˜ê²½ë³€ìˆ˜ì—ì„œ í™•ì¸ (.env íŒŒì¼)
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print("ğŸ”‘ API Key found in environment variables (local .env)")
        return api_key
    
    # 2. Streamlit secretsì—ì„œ í™•ì¸ (Streamlit Cloud)
    if HAS_STREAMLIT:
        try:
            api_key = st.secrets.get("OPENAI_API_KEY")
            if api_key:
                print("ğŸ”‘ API Key found in Streamlit secrets (cloud)")
                return api_key
        except Exception as e:
            print(f"ğŸ”´ Error accessing Streamlit secrets: {e}")
    
    print("ğŸ”´ No API Key found in .env or Streamlit secrets")
    return None


def get_llm():  # noqa: D401
    global _llm
    if _llm is None:
        api_key = get_api_key()
        if api_key:
            print(f"ğŸ”µ Creating ChatOpenAI with API key: {api_key[:10]}...")
            _llm = ChatOpenAI(temperature=0.3, model_name="gpt-4o-mini", openai_api_key=api_key)
        else:
            print("ğŸ”´ No API key available, using EchoResponder")
            _llm = EchoResponder()
    return _llm


def predict(prompt: str, context: str | None = None) -> str:
    """ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•´ LLM ì‘ë‹µ ë°˜í™˜."""
    print(f"ğŸ”µ LANGCHAIN_CHAT.PREDICT CALLED")
    print(f"ğŸ”µ PROMPT: {prompt}")
    print(f"ğŸ”µ CONTEXT: {context[:100] if context else 'None'}...")

    llm = get_llm()
    print(f"ğŸ”µ LLM TYPE: {type(llm)}")

    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    final_prompt = f"""
[ì‚¬ìš©ì ì§ˆë¬¸]
{prompt}

[ì°¸ê³  ë°ì´í„°]
{context}

---
ìœ„ ì°¸ê³  ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ì°¸ê³  ë°ì´í„°ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
    print(f"ğŸ”µ FINAL PROMPT LENGTH: {len(final_prompt)}")

    try:
        if hasattr(llm, "invoke"):
            print("ğŸ”µ USING LLM.INVOKE")
            resp = llm.invoke(final_prompt)
            print(f"ğŸ”µ RAW RESPONSE TYPE: {type(resp)}")

            # ChatOpenAI.invoke ê²½ìš° BaseMessage ë°˜í™˜ â†’ content ì¶”ì¶œ
            if hasattr(resp, "content"):
                result = resp.content  # type: ignore[attr-defined]
                print(f"ğŸ”µ EXTRACTED CONTENT: {result[:100]}...")
                return result
            # dict í˜•íƒœì¼ ê²½ìš°
            if isinstance(resp, dict) and "content" in resp:
                result = resp["content"]  # type: ignore[index]
                print(f"ğŸ”µ DICT CONTENT: {result[:100]}...")
                return result
            result = str(resp)
            print(f"ğŸ”µ STRING CONVERSION: {result[:100]}...")
            return result
        elif callable(llm):
            print("ğŸ”µ USING CALLABLE LLM")
            result = llm(final_prompt)
            print(f"ğŸ”µ CALLABLE RESULT: {result[:100]}...")
            return result
        else:
            print("ğŸ”µ LLM NOT INVOKABLE OR CALLABLE")
            return "[error] LLM unavailable"
    except Exception as e:
        print(f"ğŸ”´ LANGCHAIN_CHAT ERROR: {str(e)}")
        return f"[error] {str(e)}"
